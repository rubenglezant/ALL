{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LOAD AND PARSE  THE TWEETS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/03/2015 18:36:43\n",
      "\n",
      "CPython 2.7.10\n",
      "IPython 4.0.0\n",
      "\n",
      "compiler   : GCC 4.4.7 20120313 (Red Hat 4.4.7-1)\n",
      "system     : Linux\n",
      "release    : 3.13.0-66-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tweepy Stream Handler writes to a file containing one tweet per line. Each line follows the following structure:\n",
    "\n",
    "*@USER + | + [LAT,LON] | TIMESTAMP | TWEET*\n",
    "\n",
    "And now we proceed to turn it into a more useable file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the tweets file was so big, I processed it by chunks instead of loading all of it in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tweets_raw = pd.read_table('tweets.txt', header=None, iterator=True)\n",
    "\n",
    "while 1:\n",
    "    tweets = tweets_raw.get_chunk(10000)\n",
    "    tweets.columns = ['tweets']\n",
    "    tweets['len'] = tweets.tweets.apply(lambda x: len(x.split('|')))\n",
    "    tweets[tweets.len < 4] = np.nan\n",
    "    del tweets['len']\n",
    "    tweets = tweets[tweets.tweets.notnull()]\n",
    "    tweets['user'] = tweets.tweets.apply(lambda x: x.split('|')[0])\n",
    "    tweets['geo'] = tweets.tweets.apply(lambda x: x.split('|')[1])\n",
    "    tweets['timestamp'] = tweets.tweets.apply(lambda x: x.split('|')[2])\n",
    "    tweets['tweet'] = tweets.tweets.apply(lambda x: x.split('|')[3])\n",
    "    tweets['lat'] = tweets.geo.apply(lambda x: x.split(',')[0].replace('[',''))\n",
    "    tweets['lon'] = tweets.geo.apply(lambda x: x.split(',')[1].replace(']',''))\n",
    "    del tweets['tweets']\n",
    "    del tweets['geo']\n",
    "    tweets['lon'] = tweets.lon.convert_objects(convert_numeric=True)\n",
    "    tweets['lat'] = tweets.lat.convert_objects(convert_numeric=True)\n",
    "    tweets.to_csv('tweets.csv', mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181987, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user                 object\n",
       "timestamp    datetime64[ns]\n",
       "tweet                object\n",
       "lat                 float64\n",
       "lon                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@IkiduAuren</td>\n",
       "      <td>2015-03-29 15:58:23</td>\n",
       "      <td>Feliz tarde de Domingo. http://t.co/jxL7v5zFwd</td>\n",
       "      <td>38.842937</td>\n",
       "      <td>-0.115407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@monorex2</td>\n",
       "      <td>2015-03-29 15:59:37</td>\n",
       "      <td>Good afternoon:-D:-D</td>\n",
       "      <td>38.026032</td>\n",
       "      <td>-1.208355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Santos_Poveda</td>\n",
       "      <td>2015-03-29 16:01:29</td>\n",
       "      <td>@InkUtv @OilVirgin @RiobuenoRafael @NinaNebo @...</td>\n",
       "      <td>38.095896</td>\n",
       "      <td>-1.181909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@anittaaML</td>\n",
       "      <td>2015-03-29 16:03:46</td>\n",
       "      <td>@caarmens98 te voy a reportar por hj de p</td>\n",
       "      <td>37.992632</td>\n",
       "      <td>-1.197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@helenatovar0210</td>\n",
       "      <td>2015-03-29 16:04:46</td>\n",
       "      <td>Lucha por lo qe quieres qe les joda a los qe h...</td>\n",
       "      <td>38.055685</td>\n",
       "      <td>-1.081301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user           timestamp  \\\n",
       "1       @IkiduAuren 2015-03-29 15:58:23   \n",
       "3         @monorex2 2015-03-29 15:59:37   \n",
       "4    @Santos_Poveda 2015-03-29 16:01:29   \n",
       "6        @anittaaML 2015-03-29 16:03:46   \n",
       "7  @helenatovar0210 2015-03-29 16:04:46   \n",
       "\n",
       "                                               tweet        lat       lon  \n",
       "1     Feliz tarde de Domingo. http://t.co/jxL7v5zFwd  38.842937 -0.115407  \n",
       "3                               Good afternoon:-D:-D  38.026032 -1.208355  \n",
       "4  @InkUtv @OilVirgin @RiobuenoRafael @NinaNebo @...  38.095896 -1.181909  \n",
       "6          @caarmens98 te voy a reportar por hj de p  37.992632 -1.197700  \n",
       "7  Lucha por lo qe quieres qe les joda a los qe h...  38.055685 -1.081301  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert time zome from UTC to Spain time for further time of day analyses\n",
    "tweets.set_index('timestamp').tz_localize('UTC').tz_convert('Europe/Madrid').reset_index()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to do a heatmap, we only care about those tweets that are geocoded and whose latitude and longitud are within the Murcia area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95384, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_lon = -1.157420\n",
    "max_lon = -1.081202\n",
    "min_lat = 37.951741\n",
    "max_lat = 38.029126\n",
    "\n",
    "tweets = tweets[(tweets.lat.notnull()) & (tweets.lon.notnull())]\n",
    "\n",
    "tweets = tweets[(tweets.lon > min_lon) & (tweets.lon < max_lon) & (tweets.lat > min_lat) & (tweets.lat < max_lat)]\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the parsed tweets to use with [heatmap.py](http://www.sethoscope.net/heatmap/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/manuel/DATA/Backup/Proyectos/tweepy murcia/heatmap\n"
     ]
    }
   ],
   "source": [
    "cd ../heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tweets_heatmap','w') as file:\n",
    "    file.write(tweets[['lat','lon']].to_string(header=False, index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
